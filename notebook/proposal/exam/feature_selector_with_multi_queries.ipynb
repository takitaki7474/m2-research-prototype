{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット読み込みとfeature_table_indexesの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import random\n",
    "import sqlite3\n",
    "from typing import List, Tuple, TypeVar, Dict\n",
    "\n",
    "Dataframe = TypeVar(\"pandas.core.frame.DataFrame\")\n",
    "\n",
    "# datasetをsqliteからDataFrame形式で読み込み\n",
    "def load_dataset(dbpath=\"./ft.db\", tablename=\"feature_table\") -> Dataframe:\n",
    "    conn=sqlite3.connect(dbpath)\n",
    "    c = conn.cursor()\n",
    "    dataset = pd.read_sql('SELECT * FROM ' + tablename, conn)\n",
    "    return dataset\n",
    "\n",
    "# feature_table_indexesの初期化 (queryはランダムに選択)\n",
    "def init_ft_indexes(ft: Dataframe, queryN=1, seed=0) -> Dict[str, Dict]:\n",
    "    random.seed(seed)\n",
    "    labels = sorted(ft[\"label\"].unique())\n",
    "    ft_labelby = ft.groupby(\"label\")\n",
    "    ft_indexes = {}\n",
    "    ft_indexes[\"queries\"], ft_indexes[\"used_queries\"], ft_indexes[\"selected_data\"],  = {}, {}, {}\n",
    "    \n",
    "    for label in labels:\n",
    "        ft_indexes[\"used_queries\"][label] = []\n",
    "        ft_indexes[\"selected_data\"][label] = []\n",
    "        \n",
    "        ft = ft_labelby.get_group(label)\n",
    "        indexes = ft[\"index\"].values.tolist()\n",
    "        queries = random.sample(indexes, queryN)\n",
    "        ft_indexes[\"queries\"][label] = queries\n",
    "    \n",
    "    return ft_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List, Tuple, TypeVar, Dict\n",
    "\n",
    "Dataframe = TypeVar(\"pandas.core.frame.DataFrame\")\n",
    "Tensor = TypeVar(\"torch.Tensor\")\n",
    "NpInt64 = TypeVar(\"numpy.int64\")\n",
    "\n",
    "class DataSelector:\n",
    "    def __init__(self, dt: Dataframe, dt_indexes: Dict[str, Dict[int, List]]):\n",
    "        self.default_dt = dt\n",
    "        self.dt_indexes = copy.deepcopy(dt_indexes)\n",
    "        self.labels = sorted(dt[\"label\"].unique())\n",
    "        # 学習済みのデータを削除したdataset_table\n",
    "        self.dt = self.__init_dt(dt, dt_indexes)\n",
    "        \n",
    "    def __init_dt(self, dt: Dataframe, dt_indexes: Dict[str, Dict[int, List]]) -> Dataframe:\n",
    "        drop_indexes = []\n",
    "        for indexes in dt_indexes[\"selected_data\"].values():\n",
    "            drop_indexes += indexes\n",
    "        dt = dt.drop(index=drop_indexes)\n",
    "        return dt\n",
    "        \n",
    "    def __convert_to_tensor_image(self, json_image) -> Tensor:\n",
    "        image = json.loads(json_image)\n",
    "        image = np.array(image)\n",
    "        image = torch.from_numpy(image.astype(np.float32)).clone()\n",
    "        return image\n",
    "    \n",
    "    def drop_data(self, indexes: List):\n",
    "        self.dt = self.dt.drop(index=indexes)\n",
    "        \n",
    "    def get_dt_indexes(self) -> Dict[str, Dict[int, List]]:\n",
    "        return self.dt_indexes\n",
    "    \n",
    "    def get_dataset(self, indexes_labelby: Dict[int, List]) -> List[Tuple[Tensor, NpInt64]]:\n",
    "        dataset = []\n",
    "        dt_labelby = self.default_dt.groupby(\"label\")\n",
    "        for label in self.labels:\n",
    "            indexes = indexes_labelby[label]\n",
    "            dt = dt_labelby.get_group(label)\n",
    "            rows = dt[dt[\"index\"].isin(indexes)]\n",
    "            images = rows[\"image\"].values\n",
    "            labels = rows[\"label\"].values\n",
    "            for image, label in zip(images, labels):\n",
    "                image = self.__convert_to_tensor_image(image)\n",
    "                dataset.append((image, label))\n",
    "        return dataset\n",
    "    \n",
    "    def randomly_select_dt_indexes(self, dataN: int, seed=0) -> Dict[int, List]:\n",
    "        indexes_labelby = {}\n",
    "        dt_labelby = self.dt.groupby(\"label\")\n",
    "        for label in self.labels:\n",
    "            dt = dt_labelby.get_group(label)\n",
    "            dt = dt.sample(n=dataN, random_state=seed)\n",
    "            selected_indexes = list(dt[\"index\"].values)\n",
    "            indexes_labelby[label] = selected_indexes\n",
    "            self.dt_indexes[\"selected_data\"][label] += selected_indexes\n",
    "            self.drop_data(selected_indexes)\n",
    "        return indexes_labelby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ数:  15000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.30711856484413147, 0.19312363862991333, 0.0...</td>\n",
       "      <td>[[[-0.3176470398902893, -0.29411762952804565, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.4214461147785187, 1.198604702949524, 0.9510...</td>\n",
       "      <td>[[[-0.9764705896377563, -0.9686274528503418, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.2851516008377075, 0.20933431386947632, 0.07...</td>\n",
       "      <td>[[[0.13725495338439941, 0.13725495338439941, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.6752024292945862, 0.7612708806991577, 0.712...</td>\n",
       "      <td>[[[-0.24705880880355835, -0.27843135595321655,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.3068203926086426, 0.6951863169670105, 0.444...</td>\n",
       "      <td>[[[0.30980396270751953, 0.30980396270751953, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            feature  \\\n",
       "0      0  [0.30711856484413147, 0.19312363862991333, 0.0...   \n",
       "1      1  [0.4214461147785187, 1.198604702949524, 0.9510...   \n",
       "2      2  [0.2851516008377075, 0.20933431386947632, 0.07...   \n",
       "3      3  [0.6752024292945862, 0.7612708806991577, 0.712...   \n",
       "4      4  [0.3068203926086426, 0.6951863169670105, 0.444...   \n",
       "\n",
       "                                               image  label  \n",
       "0  [[[-0.3176470398902893, -0.29411762952804565, ...      1  \n",
       "1  [[[-0.9764705896377563, -0.9686274528503418, -...      1  \n",
       "2  [[[0.13725495338439941, 0.13725495338439941, 0...      2  \n",
       "3  [[[-0.24705880880355835, -0.27843135595321655,...      2  \n",
       "4  [[[0.30980396270751953, 0.30980396270751953, 0...      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = load_dataset(dbpath=\"./assets/ft.db\")\n",
    "print(\"データ数:  {0}\".format(len(ft)))\n",
    "ft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': {0: [1347, 2238, 2070, 8954, 4165],\n",
       "  1: [7522, 6188, 14867, 5218, 14887],\n",
       "  2: [916, 14267, 3882, 10627, 9697]},\n",
       " 'selected_data': {0: [], 1: [], 2: []},\n",
       " 'used_queries': {0: [], 1: [], 2: []}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_indexes1 = init_ft_indexes(ft=ft, queryN=5, seed=2)\n",
    "ft_indexes1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1反復目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = DataSelector(ft, ft_indexes1)\n",
    "indexes_labelby1 = selector.randomly_select_dt_indexes(dataN=200, seed=2)\n",
    "indexes_labelby2 = selector.randomly_select_dt_indexes(dataN=200, seed=2)\n",
    "ft_indexes2 = selector.get_dt_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベル0  の重複なしデータ数:  400\n",
      "ラベル1  の重複なしデータ数:  400\n",
      "ラベル2  の重複なしデータ数:  400\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"ラベル{0}  の重複なしデータ数:  {1}\".format(i, len(set(ft_indexes2[\"selected_data\"][i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2反復目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = DataSelector(ft, ft_indexes2)\n",
    "indexes_labelby3 = selector.randomly_select_dt_indexes(dataN=200, seed=0)\n",
    "indexes_labelby4 = selector.randomly_select_dt_indexes(dataN=200, seed=0)\n",
    "ft_indexes3 = selector.get_dt_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベル0  の重複なしデータ数:  800\n",
      "ラベル1  の重複なしデータ数:  800\n",
      "ラベル2  の重複なしデータ数:  800\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"ラベル{0}  の重複なしデータ数:  {1}\".format(i, len(set(ft_indexes3[\"selected_data\"][i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ数:  2400\n",
      "(tensor([[[-0.6471, -0.6000, -0.6078,  ..., -0.6392, -0.6000, -0.7412],\n",
      "         [-0.7020, -0.6078, -0.5137,  ..., -0.7255, -0.6235, -0.6627],\n",
      "         [-0.6863, -0.5451, -0.5608,  ..., -0.7098, -0.5216, -0.5216],\n",
      "         ...,\n",
      "         [ 0.5373,  0.4980,  0.4510,  ...,  0.8431,  0.9373,  0.7569],\n",
      "         [ 0.6157,  0.6784,  0.6863,  ...,  0.8745,  0.6863,  0.4275],\n",
      "         [ 0.4431,  0.4510,  0.5216,  ...,  0.6235,  0.4039,  0.3647]],\n",
      "\n",
      "        [[-0.6314, -0.5529, -0.6078,  ..., -0.6235, -0.6157, -0.6627],\n",
      "         [-0.6314, -0.5373, -0.5294,  ..., -0.7020, -0.6471, -0.6549],\n",
      "         [-0.6235, -0.4745, -0.5686,  ..., -0.6863, -0.5373, -0.5373],\n",
      "         ...,\n",
      "         [-0.8667, -0.8118, -0.7804,  ...,  0.3804,  0.2314, -0.5451],\n",
      "         [-0.9529, -0.9216, -0.7569,  ...,  0.8431,  0.1373, -0.6549],\n",
      "         [-0.7255, -0.7882, -0.5451,  ...,  0.3961, -0.0588, -0.1529]],\n",
      "\n",
      "        [[-0.6627, -0.6314, -0.7020,  ..., -0.6000, -0.6471, -0.6706],\n",
      "         [-0.7255, -0.6235, -0.5765,  ..., -0.6863, -0.6706, -0.6471],\n",
      "         [-0.7490, -0.5765, -0.6314,  ..., -0.6784, -0.5451, -0.5216],\n",
      "         ...,\n",
      "         [-0.6941, -0.6235, -0.6863,  ...,  0.5137,  0.4510, -0.3333],\n",
      "         [-0.8039, -0.6706, -0.5137,  ...,  0.8431,  0.2471, -0.5451],\n",
      "         [-0.6863, -0.6314, -0.3647,  ...,  0.4510, -0.0039, -0.1686]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "dataset = selector.get_dataset(ft_indexes3[\"selected_data\"])\n",
    "print(\"データ数:  {0}\".format(len(dataset)))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List, Tuple, TypeVar, Dict\n",
    "\n",
    "Dataframe = TypeVar(\"pandas.core.frame.DataFrame\")\n",
    "Tensor = TypeVar(\"torch.Tensor\")\n",
    "NpArrayFloat32 = TypeVar(\"numpy.ndarray.float32\")\n",
    "NpInt64 = TypeVar(\"numpy.int64\")\n",
    "FaissIndexFlatL2 = TypeVar(\"faiss.swigfaiss.IndexFlatL2\")\n",
    "\n",
    "class FeatureSelector(DataSelector):\n",
    "    def __init__(self, ft: Dataframe, ft_indexes: Dict[str, Dict[int, List]]):\n",
    "        super().__init__(ft, ft_indexes)\n",
    "        \n",
    "    def __ft_to_features(self, ft: Dataframe) -> NpArrayFloat32:\n",
    "        features = [json.loads(f) for f in ft[\"feature\"]]\n",
    "        features = np.array(features).astype(\"float32\")\n",
    "        return features\n",
    "    \n",
    "    def __indexes_to_features(self, ft: Dataframe, indexes: List[int]) -> NpArrayFloat32:\n",
    "        features = []\n",
    "        for index in indexes:\n",
    "            feature = ft[ft[\"index\"] == index][\"feature\"].iloc[0]\n",
    "            feature = json.loads(feature)\n",
    "            features.append(feature)\n",
    "        features = np.array(features).astype(\"float32\")\n",
    "        if len(features) != len(indexes): print(\"There is a feature that cannot be obtained\")\n",
    "        return features\n",
    "            \n",
    "    def __generate_faiss_index(self, vectors: NpArrayFloat32) -> FaissIndexFlatL2:\n",
    "        dim = len(vectors[0])\n",
    "        faiss_index = faiss.IndexFlatL2(dim)\n",
    "        faiss_index.add(vectors)\n",
    "        return faiss_index\n",
    "    \n",
    "    def __search_NN_ft_indexes(self, ft: Dataframe, query_ft_indexes: List[int], dataN: int) -> List[int]:\n",
    "        queries = self.__indexes_to_features(ft, query_ft_indexes)\n",
    "        features = self.__ft_to_features(ft)\n",
    "        faiss_index = self.__generate_faiss_index(features)\n",
    "        k = faiss_index.ntotal # 検索対象データ数\n",
    "        D, I = faiss_index.search(queries, k) # 近傍探索\n",
    "        \n",
    "        NN_ft_indexes = []\n",
    "        all_query_indexes = [index for indexes in self.dt_indexes[\"queries\"].values() for index in indexes]\n",
    "        for indexes in I:\n",
    "            cnt, i = 0, 0\n",
    "            while cnt < dataN:\n",
    "                ft_index = ft.iloc[indexes[i]][\"index\"]\n",
    "                i += 1\n",
    "                if ft_index in NN_ft_indexes: continue # 既に選択済みのインデックスは検索対象外\n",
    "                if ft_index in all_query_indexes: continue # クエリは検索対象外\n",
    "                NN_ft_indexes.append(ft_index)\n",
    "                cnt += 1\n",
    "                \n",
    "        return NN_ft_indexes\n",
    "    \n",
    "    def __search_FP_ft_indexes(self, ft: Dataframe, query_ft_indexes: List[int]) -> List[int]:\n",
    "        queries = self.__indexes_to_features(ft, query_ft_indexes)\n",
    "        features = self.__ft_to_features(ft)\n",
    "        faiss_index = self.__generate_faiss_index(features)\n",
    "        k = faiss_index.ntotal # 検索対象データ数\n",
    "        D, I = faiss_index.search(queries, k) # 近傍探索\n",
    "        \n",
    "        FP_ft_indexes = []\n",
    "        all_used_query_indexes = [index for indexes in self.dt_indexes[\"used_queries\"].values() for index in indexes]\n",
    "        for indexes in I:\n",
    "            for index in reversed(indexes):\n",
    "                ft_index = ft.iloc[index][\"index\"]\n",
    "                if ft_index in FP_ft_indexes: continue # 既に選択済みのインデックスは検索対象外\n",
    "                if ft_index not in all_used_query_indexes: break # 一度でも使用されたクエリは検索対象外\n",
    "            FP_ft_indexes.append(ft_index)\n",
    "        \n",
    "        return FP_ft_indexes\n",
    "                \n",
    "    def select_NN_ft_indexes(self, dataN: int) -> Dict[int, List]:\n",
    "        indexes_labelby = {}\n",
    "        ft_labelby = self.dt.groupby(\"label\")\n",
    "        \n",
    "        for label in self.labels:\n",
    "            ft = ft_labelby.get_group(label)\n",
    "            query_ft_indexes = self.dt_indexes[\"queries\"][label]\n",
    "            NN_ft_indexes = self.__search_NN_ft_indexes(ft, query_ft_indexes, dataN)\n",
    "            \n",
    "            indexes_labelby[label] = NN_ft_indexes\n",
    "            self.dt_indexes[\"selected_data\"][label] += NN_ft_indexes\n",
    "            self.dt_indexes[\"used_queries\"][label] += query_ft_indexes\n",
    "            self.drop_data(NN_ft_indexes)\n",
    "            \n",
    "        return indexes_labelby\n",
    "    \n",
    "    def update_to_FP_queries(self) -> Dict[int, List]:\n",
    "        indexes_labelby = {}\n",
    "        ft_labelby = self.dt.groupby(\"label\")\n",
    "        \n",
    "        for label in self.labels:\n",
    "            ft = ft_labelby.get_group(label)\n",
    "            query_ft_indexes = self.dt_indexes[\"queries\"][label]\n",
    "            FP_ft_indexes = self.__search_FP_ft_indexes(ft, query_ft_indexes)\n",
    "            \n",
    "            indexes_labelby[label] = FP_ft_indexes\n",
    "            self.dt_indexes[\"queries\"][label] = FP_ft_indexes\n",
    "            \n",
    "        return indexes_labelby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ数:  15000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.30711856484413147, 0.19312363862991333, 0.0...</td>\n",
       "      <td>[[[-0.3176470398902893, -0.29411762952804565, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.4214461147785187, 1.198604702949524, 0.9510...</td>\n",
       "      <td>[[[-0.9764705896377563, -0.9686274528503418, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.2851516008377075, 0.20933431386947632, 0.07...</td>\n",
       "      <td>[[[0.13725495338439941, 0.13725495338439941, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.6752024292945862, 0.7612708806991577, 0.712...</td>\n",
       "      <td>[[[-0.24705880880355835, -0.27843135595321655,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.3068203926086426, 0.6951863169670105, 0.444...</td>\n",
       "      <td>[[[0.30980396270751953, 0.30980396270751953, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            feature  \\\n",
       "0      0  [0.30711856484413147, 0.19312363862991333, 0.0...   \n",
       "1      1  [0.4214461147785187, 1.198604702949524, 0.9510...   \n",
       "2      2  [0.2851516008377075, 0.20933431386947632, 0.07...   \n",
       "3      3  [0.6752024292945862, 0.7612708806991577, 0.712...   \n",
       "4      4  [0.3068203926086426, 0.6951863169670105, 0.444...   \n",
       "\n",
       "                                               image  label  \n",
       "0  [[[-0.3176470398902893, -0.29411762952804565, ...      1  \n",
       "1  [[[-0.9764705896377563, -0.9686274528503418, -...      1  \n",
       "2  [[[0.13725495338439941, 0.13725495338439941, 0...      2  \n",
       "3  [[[-0.24705880880355835, -0.27843135595321655,...      2  \n",
       "4  [[[0.30980396270751953, 0.30980396270751953, 0...      2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"データ数:  {0}\".format(len(ft)))\n",
    "ft[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': {0: [1347, 2238, 2070, 8954, 4165],\n",
       "  1: [7522, 6188, 14867, 5218, 14887],\n",
       "  2: [916, 14267, 3882, 10627, 9697]},\n",
       " 'selected_data': {0: [], 1: [], 2: []},\n",
       " 'used_queries': {0: [], 1: [], 2: []}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_indexes1 = init_ft_indexes(ft=ft, queryN=5, seed=2)\n",
    "ft_indexes1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1反復目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector = FeatureSelector(ft, ft_indexes1)\n",
    "indexes_labelby1 = selector.select_NN_ft_indexes(dataN=50)\n",
    "indexes_labelby2 = selector.select_NN_ft_indexes(dataN=50)\n",
    "ft_indexes2 = selector.get_dt_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベル0  の重複なしデータ数:  500\n",
      "ラベル1  の重複なしデータ数:  500\n",
      "ラベル2  の重複なしデータ数:  500\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"ラベル{0}  の重複なしデータ数:  {1}\".format(i, len(set(ft_indexes2[\"selected_data\"][i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2反復目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = FeatureSelector(ft, ft_indexes2)\n",
    "indexes_labelby3 = selector.select_NN_ft_indexes(dataN=50)\n",
    "indexes_labelby4 = selector.select_NN_ft_indexes(dataN=50)\n",
    "ft_indexes3 = selector.get_dt_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベル0  の重複なしデータ数:  1000\n",
      "ラベル1  の重複なしデータ数:  1000\n",
      "ラベル2  の重複なしデータ数:  1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"ラベル{0}  の重複なしデータ数:  {1}\".format(i, len(set(ft_indexes3[\"selected_data\"][i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3反復目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = FeatureSelector(ft, ft_indexes3)\n",
    "indexes_labelby5 = selector.update_to_FP_queries() # クエリの更新\n",
    "indexes_labelby6 = selector.select_NN_ft_indexes(dataN=100)\n",
    "ft_indexes4 = selector.get_dt_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベル0  の重複なしデータ数:  1500\n",
      "ラベル1  の重複なしデータ数:  1500\n",
      "ラベル2  の重複なしデータ数:  1500\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"ラベル{0}  の重複なしデータ数:  {1}\".format(i, len(set(ft_indexes4[\"selected_data\"][i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1347, 2238, 2070, 8954, 4165], 1: [7522, 6188, 14867, 5218, 14887], 2: [916, 14267, 3882, 10627, 9697]}\n",
      "{0: [4353, 8787, 107, 11956, 10470], 1: [8833, 10055, 5380, 4324, 5368], 2: [1609, 10722, 3546, 4383, 6056]}\n"
     ]
    }
   ],
   "source": [
    "print(ft_indexes3[\"queries\"])\n",
    "print(ft_indexes4[\"queries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ数:  4500\n",
      "(tensor([[[1.0000, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 0.9843, 0.9529,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9922,  ..., 1.0000, 0.9922, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9843,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 0.9843, 0.9451,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9922,  ..., 1.0000, 0.9922, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9843,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9922,  ..., 0.9843, 0.9922, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 0.9843, 0.9529,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9922,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 0.9922, 0.9843,  ..., 1.0000, 1.0000, 1.0000]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "dataset = selector.get_dataset(ft_indexes4[\"selected_data\"])\n",
    "print(\"データ数:  {0}\".format(len(dataset)))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
